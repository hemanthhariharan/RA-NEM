{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afd520af-6091-43e7-b326-51ae21d3faf3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df026a4c-cac1-4497-b0ae-f7408c1d32ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.tseries.holiday import AbstractHolidayCalendar, Holiday, nearest_workday, sunday_to_monday, MO, TH\n",
    "import plotly_express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns', 50)\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6ef2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(r\"K:\\Valuation\\_Analysts\\Hemanth\\Python Notebooks\\Miscellaneous\\Python Analyst Engine 2.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742ffcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import date_hour_to_peak_block, date_hour_to_time_block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521a36af",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443342c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 12.5 / 100\n",
    "wn_start_date = pd.to_datetime('2015-03-01')\n",
    "wn_end_date = pd.to_datetime('2025-02-28') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924f0c22-fcb9-4329-a99c-6b39e63667ae",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de962ed-fb6e-4e6d-848f-b9bbe429d967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def season(row):\n",
    "    if row['Month'] in [12, 1, 2]:\n",
    "        return 'Winter'\n",
    "    elif row['Month'] in [6, 7, 8, 9]:\n",
    "        return 'Summer'\n",
    "    else:\n",
    "        return 'Shoulder'\n",
    "\n",
    "\n",
    "class NERCHolidayCalendar(AbstractHolidayCalendar):\n",
    "    rules = [\n",
    "        Holiday('New Year\\'s Day', month=1, day=1, observance=sunday_to_monday),\n",
    "        Holiday('Memorial Day', month=5, day=31, offset=pd.DateOffset(weekday=MO(-1))),\n",
    "        Holiday('Independence Day', month=7, day=4, observance=sunday_to_monday),\n",
    "        Holiday('Labor Day', month=9, day=1, offset=pd.DateOffset(weekday=MO(1))),\n",
    "        Holiday('Thanksgiving', month=11, day=4, offset=pd.DateOffset(weekday=TH(4))),\n",
    "        Holiday('Christmas Day', month=12, day=25, observance=sunday_to_monday)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6eb31a-5404-4126-ac82-781ca50f9c1f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Importing data and assembling df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6865e586-a600-4103-b712-7ada6395d87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'K:\\Valuation\\Wholesale for Retail\\_Full Requirements\\NEPOOL\\NSTAR\\2025-05\\Pri Hemanth\\Load\\Pri Hemanth NSTAR 2025-05 RES WeatherNorm_v6_48 - Normal weather analysis.xlsb'\n",
    "\n",
    "df_hourly = pd.read_excel(path, usecols='CZ:DA, DF:DH', skiprows=3, sheet_name='NEMA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793df56c-0a17-4e85-bf17-8eb1e0dd5df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly['Excel_Date'] = df_hourly['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7afffe7-9969-40ec-a557-271584cdcf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly['Date'] = pd.to_datetime(df_hourly['Date'], unit='D', origin='1899-12-30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8f6166-2e0a-4403-ba53-65375ab9e7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e5587f-cafa-4eb6-ad99-62a4dc4763fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6279284e-577a-4e3e-956f-5caf871d1b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly.columns=['Date', 'Hour', 'Load', 'Hub_Price', 'Delivery_Price', 'Excel_Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf6c594-488c-4551-94ad-f0d342bf6421",
   "metadata": {},
   "outputs": [],
   "source": [
    "nerc_cal = NERCHolidayCalendar()\n",
    "\n",
    "holidays = nerc_cal.holidays(start=df_hourly['Date'].min(), end=df_hourly['Date'].max())\n",
    "\n",
    "df_hourly = df_hourly.assign(\n",
    "    Month=lambda DF: DF.Date.dt.month,\n",
    "    Year=lambda DF: DF.Date.dt.year,\n",
    "    Season=lambda DF: DF.apply(season, axis=1),\n",
    ")\n",
    "\n",
    "df_hourly['Peak_block'] = df_hourly.apply(\n",
    "    lambda DF: date_hour_to_peak_block(DF['Date'], DF['Hour'], iso='ISONE'), axis=1\n",
    ")\n",
    "\n",
    "df_hourly['Time_block'] = df_hourly.apply(\n",
    "    lambda DF: date_hour_to_peak_block(DF['Date'], DF['Hour'], iso='ISONE'), axis=1\n",
    ")\n",
    "\n",
    "df_hourly = df_hourly.assign(\n",
    "    OFF=lambda DF: np.where(DF.Peak_block != '5x16', 1, 0),\n",
    "    Weekend=lambda DF: DF.Date.dt.weekday > 4,\n",
    "    Holiday=lambda DF: DF.Date.isin(holidays)\n",
    "    \n",
    ")\n",
    "\n",
    "df_hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b3d9f4-26ca-42fc-ad4b-329d481cedcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df_hourly.Date, y=df_hourly.Load, mode='lines'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7475bb9f-e2b6-4d71-9e07-57988c474e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df_hourly.Date, y=df_hourly.Delivery_Price - df_hourly.Hub_Price, mode='lines', name='Basis'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dd2038-e2fb-4166-b1dd-fc702bd323eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# px.imshow(df_hourly.pivot_table(index='Month', values='Load', columns='Year', aggfunc='mean') * 0.125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e160385-fc57-4a76-bff3-195bf6fe88a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily = df_hourly.pivot_table(index='Date', values=['Load', 'Delivery_Price'], aggfunc='mean').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143e98b5-22c0-4285-bdcd-0e7fdf70d135",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily.reset_index(inplace=True)\n",
    "\n",
    "df_daily"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be68871c-0fa9-406b-9515-be6f1d25c3bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Importing temperature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cebb73-a4fe-4219-b70a-5d430d2ed5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created additional tab to pull temperature data until 2/28/2025 for calculating \"normal\" variables\n",
    "\n",
    "df_daily_temp = pd.read_excel(path, usecols='DP, DX:DZ', skiprows=3, sheet_name='NEMA additional month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d738f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85574753-707d-4499-927d-3c54fe406267",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily_temp.columns = ['Date', 'Avg_temp', 'Max_temp', 'Min_temp']\n",
    "\n",
    "df_daily_temp.dropna(inplace=True)\n",
    "\n",
    "df_daily_temp['CDD'] = df_daily_temp.apply(lambda x: max(x['Avg_temp'] - 65, 0), axis=1)\n",
    "df_daily_temp['HDD'] = df_daily_temp.apply(lambda x: max(65 - x['Avg_temp'], 0), axis=1)\n",
    "\n",
    "df_daily_temp['CDD^2'] = df_daily_temp['CDD'] ** 2\n",
    "df_daily_temp['HDD^2'] = df_daily_temp['HDD'] ** 2\n",
    "\n",
    "df_daily_temp['CDD75'] = df_daily_temp.apply(lambda x: max(x['Max_temp'] - 75, 0), axis=1)\n",
    "df_daily_temp['HDD40'] = df_daily_temp.apply(lambda x: max(40 - x['Min_temp'], 0), axis=1)\n",
    "\n",
    "df_daily_temp['CDDLag'] = df_daily_temp['CDD'].shift(1) * 0.75 + df_daily_temp['CDD'].shift(2) * 0.25\n",
    "df_daily_temp['HDDLag'] = df_daily_temp['HDD'].shift(1) * 0.75 + df_daily_temp['HDD'].shift(2) * 0.25\n",
    "\n",
    "df_daily_temp['Date'] = pd.to_datetime(df_daily_temp['Date'], unit='D', origin='1899-12-30') # Converting Excel Date to Pandas datetime\n",
    "df_daily_temp['Day'] = df_daily_temp.Date.dt.day\n",
    "# df_daily_temp['Month'] = df_daily_temp.Date.dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2689fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date_filter = (df_daily_temp.Date > wn_start_date) & (df_daily_temp.Date < wn_end_date)\n",
    "\n",
    "# df_daily_temp = df_daily_temp[date_filter]\n",
    "\n",
    "df_daily_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d883bfbc-6ab1-44be-be37-6a9214c82f8e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Merging with temperature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d588fb-e38b-4e39-981c-e2471a36e51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily = df_daily.merge(right=df_daily_temp, how='outer', on='Date', validate='one_to_one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ec165a-99af-4a75-ad56-8c7f64a799ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily = df_daily.merge(right=df_hourly[['Date', 'Month', 'Season', 'Weekend', 'Holiday', 'Excel_Date']], how='inner', on='Date', validate='one_to_many').drop_duplicates()\n",
    "\n",
    "# df_daily = df_daily.merge(right=df_hourly[['Date', 'Month', 'Season', 'Excel_Date']], how='inner', on='Date', validate='one_to_many').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bada805-7eb8-4894-8706-4c5e62898cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94941ee9-f7ec-457e-8c9c-1fef2bb103ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding additional variables for regression\n",
    "\n",
    "df_daily['Day'] = df_daily['Date'].dt.day\n",
    "\n",
    "df_daily['CDD'] = df_daily.apply(lambda x: max(x['Avg_temp'] - 65, 0), axis=1)\n",
    "df_daily['HDD'] = df_daily.apply(lambda x: max(65 - x['Avg_temp'], 0), axis=1)\n",
    "\n",
    "df_daily['CDD^2'] = df_daily['CDD'] ** 2\n",
    "df_daily['HDD^2'] = df_daily['HDD'] ** 2\n",
    "\n",
    "df_daily['CDD75'] = df_daily.apply(lambda x: max(x['Max_temp'] - 75, 0), axis=1)\n",
    "df_daily['HDD40'] = df_daily.apply(lambda x: max(40 - x['Min_temp'], 0), axis=1)\n",
    "\n",
    "df_daily['CDDLag'] = df_daily['CDD'].shift(1) * 0.75 + df_daily['CDD'].shift(2) * 0.25\n",
    "df_daily['HDDLag'] = df_daily['HDD'].shift(1) * 0.75 + df_daily['HDD'].shift(2) * 0.25\n",
    "\n",
    "df_daily['Covid'] = df_daily.apply(lambda x: x['Date'] > pd.to_datetime('2020-02-29'), axis=1)\n",
    "df_daily['Covid_Date'] = df_daily.apply(lambda x: x['Excel_Date'] if(x['Covid'] == 1) else 0, axis=1)\n",
    "\n",
    "for i in range(12): # indicator variables for months\n",
    "    col_name = 'Month' + str(i + 1)\n",
    "    df_daily[col_name] = df_daily.Date.dt.month == (i + 1)\n",
    "\n",
    "df_daily['OFF'] = df_daily.apply(lambda x: (x['Weekend'] == True) | (x['Holiday'] == True), axis=1)\n",
    "\n",
    "# df_daily['OFF'] = df_daily.apply(lambda DF: DF['Peak_block'] != '5x16', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66233d0a-32a1-4b8a-a7dd-f4bf70e96502",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily.fillna(method='bfill', inplace=True)\n",
    "\n",
    "df_daily"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3caeedd",
   "metadata": {},
   "source": [
    "# Calculating normal weather variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d55cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_filter = (df_daily_temp.Date > wn_start_date) & (df_daily_temp.Date < wn_end_date)\n",
    "\n",
    "df_daily_temp['Month'] = df_daily_temp.Date.dt.month # adding month for generating pivot tables below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7203a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_temp_normal = df_daily_temp[date_filter].pivot_table(index='Day', columns='Month', values='Avg_temp', aggfunc='mean')\n",
    "min_temp_normal = df_daily_temp[date_filter].pivot_table(index='Day', columns='Month', values='Min_temp', aggfunc='mean')\n",
    "max_temp_normal = df_daily_temp[date_filter].pivot_table(index='Day', columns='Month', values='Max_temp', aggfunc='mean')\n",
    "\n",
    "CDD_normal = df_daily_temp[date_filter].pivot_table(index='Day', columns='Month', values='CDD', aggfunc='mean')\n",
    "HDD_normal = df_daily_temp[date_filter].pivot_table(index='Day', columns='Month', values='HDD', aggfunc='mean')\n",
    "\n",
    "# This calculates the  CDD^2_normal and HDD^2_normal by averaging the history\n",
    "# CDD2_normal = df_daily_temp[date_filter].pivot_table(index='Day', columns='Month', values='CDD', aggfunc='mean')\n",
    "# HDD2_normal = df_daily_temp[date_filter].pivot_table(index='Day', columns='Month', values='HDD', aggfunc='mean')\n",
    "##########################################################################################\n",
    "\n",
    "CDD75_normal = df_daily_temp[date_filter].pivot_table(index='Day', columns='Month', values='CDD75', aggfunc='mean')\n",
    "HDD40_normal = df_daily_temp[date_filter].pivot_table(index='Day', columns='Month', values='HDD40', aggfunc='mean')\n",
    "\n",
    "CDDLag_normal = df_daily_temp[date_filter].pivot_table(index='Day', columns='Month', values='CDDLag', aggfunc='mean')\n",
    "HDDLag_normal = df_daily_temp[date_filter].pivot_table(index='Day', columns='Month', values='HDDLag', aggfunc='mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3203c49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_daily[(df_daily.Day == 1) & (df_daily.Month == 1)]['Avg_temp'].mean()\n",
    "\n",
    "avg_temp_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc70d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily['Avg_temp_normal'] = df_daily.apply(lambda x: avg_temp_normal.loc[x['Day'], x['Month']], axis=1)\n",
    "df_daily['Min_temp_normal'] = df_daily.apply(lambda x: min_temp_normal.loc[x['Day'], x['Month']], axis=1)\n",
    "df_daily['Max_temp_normal'] = df_daily.apply(lambda x: max_temp_normal.loc[x['Day'], x['Month']], axis=1)\n",
    "\n",
    "df_daily['CDD_normal'] = df_daily.apply(lambda x: CDD_normal.loc[x['Day'], x['Month']], axis=1)\n",
    "df_daily['HDD_normal'] = df_daily.apply(lambda x: HDD_normal.loc[x['Day'], x['Month']], axis=1)\n",
    "\n",
    "df_daily['CDD75_normal'] = df_daily.apply(lambda x: CDD75_normal.loc[x['Day'], x['Month']], axis=1)\n",
    "df_daily['HDD40_normal'] = df_daily.apply(lambda x: HDD40_normal.loc[x['Day'], x['Month']], axis=1)\n",
    "\n",
    "# This can be used if we want the CDD^2_normal and HDD^2_normal by averaging history\n",
    "# df_daily['CDD^2_normal'] = df_daily.apply(lambda x: CDD2_normal.loc[x['Day'], x['Month']], axis=1)\n",
    "# df_daily['HDD^2_normal'] = df_daily.apply(lambda x: HDD2_normal.loc[x['Day'], x['Month']], axis=1)\n",
    "\n",
    "# This squares CDD_normal and HDD_normal to get the CDD^2_normal and HDD^2_normal\n",
    "df_daily['CDD^2_normal'] = df_daily['CDD_normal'] ** 2\n",
    "df_daily['HDD^2_normal'] = df_daily['HDD_normal'] ** 2\n",
    "\n",
    "df_daily['CDDLag_normal'] = df_daily.apply(lambda x: CDDLag_normal.loc[x['Day'], x['Month']], axis=1)\n",
    "df_daily['HDDLag_normal'] = df_daily.apply(lambda x: HDDLag_normal.loc[x['Day'], x['Month']], axis=1)\n",
    "\n",
    "df_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aef0028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just doing an aggregated version of the normal weather variables to come up with an equation of load as a function of price \n",
    "\n",
    "df_daily[\n",
    "    [\n",
    "        'Date',\n",
    "        'Avg_temp_normal',\n",
    "        'Min_temp_normal',\n",
    "        'Max_temp_normal',\n",
    "        'CDD_normal',\n",
    "        'HDD_normal',\n",
    "        'CDD75_normal',\n",
    "        'HDD40_normal',\n",
    "        'CDD^2_normal',\n",
    "        'HDD^2_normal',\n",
    "        'CDDLag_normal',\n",
    "        'HDDLag_normal'\n",
    "\n",
    "    ]\n",
    "].assign(\n",
    "    Month=lambda DF: DF.Date.dt.month\n",
    ").drop(\n",
    "    columns='Date'\n",
    ").groupby('Month').mean().loc[6] # For June as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd443d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_daily[(df_daily.Month == 1) & (df_daily.Day == 1)]['Avg_temp'][0:11].sum() / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352f846e-5ee5-4ad5-837c-dc2cadde3fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting these columns to 0 to ensure matrix is invertible\n",
    "\n",
    "df_daily_summer = df_daily[df_daily.Season == 'Summer']\n",
    "df_daily_summer.loc[:, 'Month8'] = False\n",
    "\n",
    "df_daily_winter = df_daily[df_daily.Season == 'Winter']\n",
    "df_daily_winter.loc[:, 'Month2'] = False\n",
    "\n",
    "df_daily_shoulder = df_daily[df_daily.Season == 'Shoulder']\n",
    "df_daily_shoulder.loc[:, 'Month3'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49b2fa8-81da-4678-a08f-20dfc9b38cfe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Summer Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b3a765-278b-43bd-a98f-9550fdec1a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training the regression model - as an experiment, also adding the Delivery_Price\n",
    "regression_vars_summer = ['Excel_Date', 'OFF', 'CDD', 'CDD^2', 'CDDLag', 'CDD75', 'Month6', 'Month7', 'Month8', 'Month9', 'Covid', 'Covid_Date', 'Delivery_Price']\n",
    "\n",
    "# For predicting the \"normal\" load\n",
    "regression_vars_summer_normal = ['Excel_Date', 'OFF', 'CDD_normal', 'CDD^2_normal', 'CDDLag_normal', 'CDD75_normal', 'Month6', 'Month7', 'Month8', 'Month9', 'Covid', 'Covid_Date','Delivery_Price']\n",
    "\n",
    "# Fitting the regression model\n",
    "regressor_summer = LinearRegression().fit(df_daily_summer[regression_vars_summer], df_daily_summer.Load.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed31d39a-8063-4ddd-bbb4-71b49b3a3b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting summer load (what the WN calls forecasted load/regression load)\n",
    "y_pred_summer = regressor_summer.predict(df_daily_summer[regression_vars_summer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb3deb9-f3ea-4fe4-a237-3cb7e559f9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating residuals for the summer\n",
    "residuals_summer = df_daily_summer.Load - y_pred_summer.reshape(-1, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8694ba31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns so that same df can be used for predicting the \"normal\" load\n",
    "df_daily_summer_normal = df_daily_summer[regression_vars_summer_normal].rename(columns=dict(zip(regression_vars_summer_normal, regression_vars_summer)))\n",
    "\n",
    "# Incorporating the residuals into the predicted \"normal\" load\n",
    "y_pred_summer_normal = regressor_summer.predict(df_daily_summer_normal).reshape(-1, ) + residuals_summer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0149d868-7aaf-4ae3-8ad8-19a802aaab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df_daily_summer.Avg_temp, y=df_daily_summer.Load, mode='markers', name='Summer load'))\n",
    "fig.add_trace(go.Scatter(x=df_daily_summer.Avg_temp.values, y=y_pred_summer.reshape(-1, ), mode='markers', name='Regression load'))\n",
    "fig.add_trace(go.Scatter(x=df_daily_summer.Avg_temp.values, y=y_pred_summer_normal, mode='markers', name='Normal load')) \n",
    "# Had to reshape the regression output to make the plot work\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5b2b95-27c1-485b-8846-ca5ce92051f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing out regression coefficients, intercept and R2\n",
    "\n",
    "for i in range(len(regression_vars_summer)):\n",
    "    print(regression_vars_summer[i], round(regressor_summer.coef_[0, i], 3))\n",
    "\n",
    "print('Intercept', round(regressor_summer.intercept_[0], 0))\n",
    "\n",
    "print('R2 score:', round(r2_score(y_pred_summer, df_daily_summer.Load), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d78fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "(regressor_summer.coef_ * np.array([[0, 0, 3.6477, 16.28, 3.41, 3.29, 1, 0, 0, 0, 1, 0, 0]])).sum() + 199"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77ab918-24ad-4b43-b446-d7d0cdd5c09a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Winter Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109d4ef8-7213-41b5-9703-6def981925b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training the regression model - as an experiment, also adding the Delivery_Price\n",
    "regression_vars_winter = ['Excel_Date', 'OFF', 'HDD', 'HDD^2', 'HDDLag', 'HDD40', 'Month1', 'Month2', 'Month12', 'Covid', 'Covid_Date', 'Delivery_Price']\n",
    "\n",
    "# For predicting the \"normal\" load - as an experiment, also adding the Delivery_Price\n",
    "regression_vars_winter_normal = ['Excel_Date', 'OFF', 'HDD_normal', 'HDD^2_normal', 'HDDLag_normal', 'HDD40_normal', 'Month1', 'Month2', 'Month12', 'Covid', 'Covid_Date', 'Delivery_Price']\n",
    "\n",
    "# Fitting the regression model\n",
    "regressor_winter = LinearRegression().fit(df_daily_winter[regression_vars_winter], df_daily_winter.Load.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b251210-b937-48be-8116-1f45a720185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting winter load (what the WN calls forecasted load/regression load)\n",
    "y_pred_winter = regressor_winter.predict(df_daily_winter[regression_vars_winter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44e5baa-3524-4709-9346-92b80b50899e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating residuals for the winter\n",
    "residuals_winter = df_daily_winter.Load - y_pred_winter.reshape(-1, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fde1487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns so that same df can be used for predicting the \"normal\" load\n",
    "df_daily_winter_normal = df_daily_winter[regression_vars_winter_normal].rename(columns=dict(zip(regression_vars_winter_normal, regression_vars_winter)))\n",
    "\n",
    "# Incorporating the residuals into the predicted \"normal\" load\n",
    "y_pred_winter_normal = regressor_winter.predict(df_daily_winter_normal).reshape(-1, ) + residuals_winter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe3f54c-db6a-4dd1-bbb1-754ef02bef74",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df_daily_winter.Avg_temp, y=df_daily_winter.Load, mode='markers', name='Winter load'))\n",
    "fig.add_trace(go.Scatter(x=df_daily_winter.Avg_temp.values, y=y_pred_winter.reshape(-1, ), mode='markers', name='Regression')) \n",
    "fig.add_trace(go.Scatter(x=df_daily_winter.Avg_temp.values, y=y_pred_winter_normal, mode='markers', name='Normal load'))\n",
    "# Had to reshape the regression output to make the plot work\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530f91ed-c067-4b49-b7b2-d66f94fb3d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(regression_vars_winter)):\n",
    "    print(regression_vars_winter[i], round(regressor_winter.coef_[0, i], 3))\n",
    "\n",
    "print('Intercept', round(regressor_winter.intercept_[0], 0))\n",
    "\n",
    "print('R2 score:', round(r2_score(y_pred_winter.reshape(-1, ), df_daily_winter.Load), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc0dc72-e057-4866-8e50-c29d29be46a7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Shoulder Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a0c7f8-bb11-4041-99c1-38a20156bc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training the regression model - as an experiment, also adding the Delivery_Price\n",
    "regression_vars_shoulder = ['Excel_Date', 'OFF', 'CDD', 'CDD^2', 'CDDLag', 'HDD', 'HDD^2', 'HDDLag', 'HDD40', 'Month3', 'Month4', 'Month5', 'Month10', 'Month11', 'Covid', 'Covid_Date', 'Delivery_Price']\n",
    "\n",
    "# For predicting the \"normal\" load - as an experiment, also adding the Delivery_Price\n",
    "regression_vars_shoulder_normal = ['Excel_Date', 'OFF', 'CDD_normal', 'CDD^2_normal', 'CDDLag_normal', 'HDD_normal', 'HDD^2_normal', 'HDDLag_normal', 'HDD40_normal', 'Month3', 'Month4', 'Month5', 'Month10', 'Month11', 'Covid', 'Covid_Date', 'Delivery_Price']\n",
    "\n",
    "# Fitting the regression model\n",
    "regressor_shoulder = LinearRegression().fit(df_daily_shoulder[regression_vars_shoulder], df_daily_shoulder.Load.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50aecee-5971-4774-bcf8-eb183865f536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting shoulder load (what the WN calls forecasted load/regression load)\n",
    "y_pred_shoulder = regressor_shoulder.predict(df_daily_shoulder[regression_vars_shoulder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3a4e8b-d1fe-4ec8-98fb-c7e8e4488b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating residuals for the shoulder\n",
    "residuals_shoulder = df_daily_shoulder.Load - y_pred_shoulder.reshape(-1, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d12efb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns so that same df can be used for predicting the \"normal\" load\n",
    "df_daily_shoulder_normal = df_daily_shoulder[regression_vars_shoulder_normal].rename(columns=dict(zip(regression_vars_shoulder_normal, regression_vars_shoulder)))\n",
    "\n",
    "# Incorporating the residuals into the predicted \"normal\" load\n",
    "y_pred_shoulder_normal = regressor_shoulder.predict(df_daily_shoulder_normal).reshape(-1, ) + residuals_shoulder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e0e621-360f-4b6d-b49d-72368f5afe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df_daily_shoulder.Avg_temp, y=df_daily_shoulder.Load, mode='markers', name='Shoulder load'))\n",
    "fig.add_trace(go.Scatter(x=df_daily_shoulder.Avg_temp.values, y=y_pred_shoulder.reshape(-1, ), mode='markers', name='Regression'))\n",
    "fig.add_trace(go.Scatter(x=df_daily_shoulder.Avg_temp.values, y=y_pred_shoulder_normal, mode='markers', name='Normal load')) \n",
    "# Had to reshape the regression output to make the plot work\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da00b13-fcde-4788-90a8-f87095d2cb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(regression_vars_shoulder)):\n",
    "    print(regression_vars_shoulder[i], round(regressor_shoulder.coef_[0, i], 3))\n",
    "\n",
    "print('Intercept', round(regressor_shoulder.intercept_[0], 3))\n",
    "\n",
    "print('R2 score:', round(r2_score(y_pred_shoulder.reshape(-1, ), df_daily_shoulder.Load), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f234ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For summer, winter and shoulder - I know why my R^2 doesn't exactly tie to the WN model even though the coefficients are very close. \n",
    "# It is because of the difference in normal weather calculation - difference in the range of temperatures used to calculate normal weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13c35b4-9c7f-461e-bad5-3928347bf025",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Combined plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58ba342-6548-4b87-a0d3-52faa36fc557",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "# Had to reshape the regression output to make the plot work\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=pd.concat([df_daily_summer.Avg_temp, df_daily_winter.Avg_temp, df_daily_shoulder.Avg_temp]),\n",
    "        y=pd.concat([df_daily_summer.Load, df_daily_winter.Load, df_daily_shoulder.Load]),\n",
    "        mode='markers',\n",
    "        name='Load'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=np.concatenate((df_daily_summer.Avg_temp.values, df_daily_winter.Avg_temp.values, df_daily_shoulder.Avg_temp.values)),\n",
    "        y=np.concatenate((y_pred_summer, y_pred_winter, y_pred_shoulder)).reshape(-1, ),\n",
    "        mode='markers',\n",
    "        name='Regression'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=np.concatenate((df_daily_summer.Avg_temp.values, df_daily_winter.Avg_temp.values, df_daily_shoulder.Avg_temp.values)),\n",
    "        y=np.concatenate((y_pred_summer_normal, y_pred_winter_normal, y_pred_shoulder_normal)).reshape(-1, ),\n",
    "        mode='markers',\n",
    "        name='Normal'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(title='Raw load, Regressed load and Normal load vs Temperature')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7344e59-253d-41c0-a2b8-fb4bff89d9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=pd.concat([df_daily_summer.Date, df_daily_winter.Date, df_daily_shoulder.Date]), \n",
    "        y=np.concatenate((residuals_summer, residuals_winter, residuals_shoulder)), \n",
    "        mode='markers'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(title='Residuals vs Time')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa83af50-2d72-41ba-8d53-cd89954aa289",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=np.concatenate((df_daily_summer.Avg_temp.values, df_daily_winter.Avg_temp.values, df_daily_shoulder.Avg_temp.values)), \n",
    "        y=np.concatenate((residuals_summer, residuals_winter, residuals_shoulder)),\n",
    "        mode='markers', \n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(title='Residuals vs Avg Temp')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a1da71",
   "metadata": {},
   "source": [
    "# Generating WN output tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e97b3e",
   "metadata": {},
   "source": [
    "## Incorporating regression results into df_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259059db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WN_results = pd.DataFrame(\n",
    "    {\n",
    "        'Date': pd.concat([df_daily_summer.Date, df_daily_winter.Date, df_daily_shoulder.Date]),\n",
    "        'WN_load_with_residuals': np.concatenate((y_pred_summer_normal, y_pred_winter_normal, y_pred_shoulder_normal)).reshape(-1, ),\n",
    "        'Predicted_load': np.concatenate((y_pred_summer, y_pred_winter, y_pred_shoulder)).reshape(-1, ), # or regression load\n",
    "        'Residuals': np.concatenate((residuals_summer, residuals_winter, residuals_shoulder)).reshape(-1, ),\n",
    "        }\n",
    "        )\n",
    "\n",
    "df_WN_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e50f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging df_daily with WN results\n",
    "\n",
    "df_daily = df_daily.merge(df_WN_results, how='outer', on='Date', validate='1:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb97630",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily['Adjustments'] = df_daily['WN_load_with_residuals'] - df_daily['Load']\n",
    "df_daily['Year'] = df_daily.Date.dt.year # including year for creating summary pivot tables\n",
    "df_daily['WN_load_without_residuals'] = df_daily['WN_load_with_residuals'] - df_daily['Residuals']\n",
    "\n",
    "# df_daily[df_daily.Date == pd.to_datetime('2014-06-01')]\n",
    "\n",
    "df_daily"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963ddfc7",
   "metadata": {},
   "source": [
    "## WN load with residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecb52b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size * df_daily.pivot_table(index='Month', columns='Year', values='WN_load_with_residuals')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8902c78",
   "metadata": {},
   "source": [
    "## Predicted/Regressed load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddeb13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(block_size * df_daily.pivot_table(index='Month', columns='Year', values='Predicted_load'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7d915d",
   "metadata": {},
   "source": [
    "## Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7850a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(block_size * df_daily.pivot_table(index='Month', columns='Year', values='Residuals'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36dbd85",
   "metadata": {},
   "source": [
    "## Residuals as %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4896f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_daily.pivot_table(index='Month', columns='Year', values='Residuals') / df_daily.pivot_table(index='Month', columns='Year', values='Predicted_load')) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8eb138",
   "metadata": {},
   "source": [
    "## Historical load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0ad4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily.pivot_table(index='Month', columns='Year', values='Load') * block_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ae19ac",
   "metadata": {},
   "source": [
    "## Adjustments as %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d8ad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_daily.pivot_table(index='Month', columns='Year', values='Adjustments') / df_daily.pivot_table(index='Month', columns='Year', values='Load')) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c37f7e1",
   "metadata": {},
   "source": [
    "## WN load without residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad0036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(block_size * df_daily.pivot_table(index='Month', columns='Year', values='WN_load_without_residuals'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12e4664",
   "metadata": {},
   "source": [
    "# Load Flex Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7afdbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily['Load_flex'] = (df_daily['WN_load_with_residuals'] - df_daily['Load']) / df_daily['Load']\n",
    "\n",
    "df_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d444f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily.pivot_table(index='Month', columns='Year', values='Load_flex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49da324-f852-463a-8352-e91a9dd44ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(df_daily.pivot_table(index='Month', columns='Year', values='Load_flex'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e1273b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
